{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.3 - Detecting Fake Reviews.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPL2lRT8Zw2i85YHGDZbZ4l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"o7R5wj0jhcY1","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1643556884056,"user_tz":300,"elapsed":314,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}},"outputId":"028aebf3-598a-408d-e2c2-5135b76eccdf"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f259fdc5-2101-4b36-bf9b-3ec70f9e8415\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>deceptive</th>\n","      <th>hotel</th>\n","      <th>polarity</th>\n","      <th>source</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1600</td>\n","      <td>1600</td>\n","      <td>1600</td>\n","      <td>1600</td>\n","      <td>1600</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1596</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>deceptive</td>\n","      <td>sheraton</td>\n","      <td>positive</td>\n","      <td>MTurk</td>\n","      <td>My daughter and I woke in the morning wanting ...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>800</td>\n","      <td>80</td>\n","      <td>800</td>\n","      <td>800</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f259fdc5-2101-4b36-bf9b-3ec70f9e8415')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f259fdc5-2101-4b36-bf9b-3ec70f9e8415 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f259fdc5-2101-4b36-bf9b-3ec70f9e8415');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        deceptive  ...                                               text\n","count        1600  ...                                               1600\n","unique          2  ...                                               1596\n","top     deceptive  ...  My daughter and I woke in the morning wanting ...\n","freq          800  ...                                                  2\n","\n","[4 rows x 5 columns]"]},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from google.colab import files\n","import pandas as pd\n","import io\n","\n","trip_advisor = pd.read_csv('https://raw.githubusercontent.com/gburtch/BA865-2022/main/Week%203/datasets/deceptive-opinion.csv')\n","\n","#uploaded = files.upload()\n","#trip_advisor = pd.read_csv(io.BytesIO(uploaded['deceptive-opinion.csv']))\n","trip_advisor.describe(include='all')"]},{"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing.text import text_to_word_sequence\n","\n","# The dataset is perfectly balanced, so 50% accuracy will be equivalent to a random guess. \n","labels = np.where(trip_advisor['deceptive']=='truthful',0,1)\n","\n","text = []\n","for i in range(len(trip_advisor)):\n","  text.append(text_to_word_sequence(trip_advisor['text'][i])) # This strips punctuation, odd characters, and makes things lower-case. "],"metadata":{"id":"_8dsXMrbk445","executionInfo":{"status":"ok","timestamp":1643556889016,"user_tz":300,"elapsed":293,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["We could strip out infrequent (or overly frequent) terms if we wanted to, like this..."],"metadata":{"id":"PFNRsZqu3JNl"}},{"cell_type":"code","source":["# Here's how we could strip out infrequent items if we wanted to.\n","min_freq = 1\n","\n","word_freq = {}\n","for review in text:\n","  for term in review:\n","    try:\n","        word_freq[term] = word_freq[term]+1\n","    except KeyError:\n","        word_freq[term] = 1\n","\n","# This is where we can play with how frequent a word has to be to enter our model.\n","max_freq = max(i for i in word_freq.values())\n","for i in range(len(text)):\n","  text[i] = [term for term in text[i] if word_freq[term] >= min_freq & word_freq[term] <= max_freq]"],"metadata":{"id":"kySkp5Gi2_yv","executionInfo":{"status":"ok","timestamp":1643556892132,"user_tz":300,"elapsed":400,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Here, we are making our integer codings for the text tokens."],"metadata":{"id":"E4bJC8IWkkKa"}},{"cell_type":"code","source":["# We declare a set, which we populate from terms from the corpus, one by one. \n","# Sets only allow 'unique' values. \n","unique_terms = {term for review in text for term in review}\n","print(f'We have {len(unique_terms)} unique tokens in our dataset.')\n","\n","# We can then easily make a term-integer dictionary and an integer-term dictionary (for reverse lookup)\n","word_index = {term: number for number, term in enumerate(unique_terms)}\n","reverse_index = {number: term for number, term in enumerate(unique_terms)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4XcXwCDki8A","executionInfo":{"status":"ok","timestamp":1643556893794,"user_tz":300,"elapsed":189,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}},"outputId":"b18470f3-8659-4c07-9e24-dd2ed6246d4f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["We have 10275 unique tokens in our dataset.\n"]}]},{"cell_type":"markdown","source":["One-hot encoding the text can be done very explicitly now, as a nested loop."],"metadata":{"id":"mvIDdBCaiY1f"}},{"cell_type":"code","source":["def vectorize_sequences(sequences, dimension=len(unique_terms)): \n","    # Make our blank matrix of 0's to store hot encodings.\n","    results = np.zeros((len(sequences), dimension))\n","\n","    # For each observation and element in that observation,\n","    # Update the blank matrix to a 1 at row obs, column element value.\n","    for i, sequence in enumerate(sequences):\n","        for j in sequence:\n","            results[i, word_index[j]] = 1.\n","    return results\n","\n","text_onehot = vectorize_sequences(text)\n","\n","text_onehot.shape"],"metadata":{"id":"NdGsdLNxqyyf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643556896414,"user_tz":300,"elapsed":317,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}},"outputId":"97360279-d606-4737-fe4d-8fe56173422c"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1600, 10275)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Don't forget we have a few other features in the data. It's not just about the review text... "],"metadata":{"id":"4MONCGalmvsS"}},{"cell_type":"code","source":["# One hot encoding the hotels. \n","hotel_dict = {hotel : index for index, hotel in enumerate(set(trip_advisor['hotel']))}\n","hotels = []\n","for hotel in trip_advisor['hotel']:\n","  hotels.append(hotel_dict[hotel])\n","\n","hotels_onehot = keras.utils.to_categorical(np.array(hotels))\n","\n","# One hot encoding the review source\n","source_int = np.where(np.array(trip_advisor['source'])=='MTurk',0,np.where(np.array(trip_advisor['source'])=='TripAdvisor',1,2))\n","source_onehot = keras.utils.to_categorical(source_int)\n","\n","# Binarizing the polarity\n","polarity_bin = np.where(np.array(trip_advisor['polarity'])==\"negative\",0,1).reshape(1600,1)\n","\n","# Last step, we shuffle the data\n","data_onehot = np.concatenate((labels.reshape(1600,1),text_onehot,hotels_onehot,polarity_bin),axis=1)\n","np.random.shuffle(data_onehot)\n","\n","# Then we pull out predictors and labels.\n","predictors = data_onehot[:,1:]\n","labels = data_onehot[:,0]\n"],"metadata":{"id":"Jr3WnmXhmzcc","executionInfo":{"status":"ok","timestamp":1643556898990,"user_tz":300,"elapsed":273,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Now we can fit out model to the resulting data. Once again we have k-fold cross validation here. This model is incapable of learning anything much (validation accuracy never really surpasses 55-56%, and the loss is always increasing in training)."],"metadata":{"id":"pR9UI8U4zkjm"}},{"cell_type":"code","source":["from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","\n","def build_model():\n","    model = keras.Sequential([\n","        # This is essentially a dense layer that mimics word embedding; we are reducing the one-hot encoded text (10,000+ one-hot tokens) down to 750 latent dimensions.\n","        layers.Dense(750, activation=\"linear\"),\n","        layers.Dense(50, activation=\"relu\",kernel_regularizer=\"l2\"),\n","        layers.Dense(5, activation=\"relu\"),\n","        layers.Dense(1, activation=\"sigmoid\")\n","    ])\n","    model.compile(optimizer=keras.optimizers.Adadelta(learning_rate=0.01), loss=\"binary_crossentropy\", metrics=[keras.metrics.BinaryAccuracy(threshold=0.5)])\n","    return model\n","\n","model = build_model()\n","\n","data_train = predictors[:1200]\n","labels_train = labels[:1200]\n","data_test = predictors[1200:]\n","labels_test = labels[1200:]\n","\n","k = 4\n","num_validation_samples = len(data_train) // k\n","num_epochs = 50\n","batch_sizes = 25\n","all_loss_histories = []\n","all_val_loss_histories = []  \n","all_acc_histories = []\n","all_val_acc_histories = []\n"," \n","for fold in range(k):\n","    validation_data = data_train[num_validation_samples * fold:\n","                           num_validation_samples * (fold + 1)]\n","    validation_targets = labels_train[num_validation_samples * fold:\n","                           num_validation_samples * (fold + 1)]\n","    training_data = np.concatenate([\n","        data_train[:num_validation_samples * fold],\n","        data_train[num_validation_samples * (fold + 1):]])\n","    training_targets = np.concatenate([\n","        labels_train[:num_validation_samples * fold],\n","        labels_train[num_validation_samples * (fold + 1):]])\n","    model = build_model()\n","    history = model.fit(training_data, training_targets, \n","                        validation_data = (validation_data,validation_targets), \n","                        epochs=num_epochs, batch_size=batch_sizes)\n","    val_loss_history = history.history['val_loss']\n","    val_acc_history = history.history['val_binary_accuracy']\n","    loss_history = history.history['loss']\n","    acc_history = history.history['binary_accuracy']\n","    all_val_loss_histories.append(val_loss_history)\n","    all_loss_histories.append(loss_history)\n","    all_val_acc_histories.append(val_acc_history)\n","    all_acc_histories.append(acc_history)\n","\n","average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n","average_val_loss_history = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n","average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n","average_val_acc_history = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]"],"metadata":{"id":"8sEQSBHNiGSo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b5d5570-e88a-4820-e96f-6f41207d0ff8","executionInfo":{"status":"ok","timestamp":1643557015991,"user_tz":300,"elapsed":114202,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","36/36 [==============================] - 3s 27ms/step - loss: 1.6311 - binary_accuracy: 0.4833 - val_loss: 1.6237 - val_binary_accuracy: 0.5200\n","Epoch 2/50\n","36/36 [==============================] - 1s 19ms/step - loss: 1.6157 - binary_accuracy: 0.5500 - val_loss: 1.6116 - val_binary_accuracy: 0.5400\n","Epoch 3/50\n","36/36 [==============================] - 1s 19ms/step - loss: 1.6002 - binary_accuracy: 0.6244 - val_loss: 1.5987 - val_binary_accuracy: 0.5700\n","Epoch 4/50\n","36/36 [==============================] - 1s 17ms/step - loss: 1.5837 - binary_accuracy: 0.6844 - val_loss: 1.5844 - val_binary_accuracy: 0.6367\n","Epoch 5/50\n","36/36 [==============================] - 1s 16ms/step - loss: 1.5658 - binary_accuracy: 0.7356 - val_loss: 1.5686 - val_binary_accuracy: 0.6867\n","Epoch 6/50\n","36/36 [==============================] - 1s 15ms/step - loss: 1.5471 - binary_accuracy: 0.7878 - val_loss: 1.5520 - val_binary_accuracy: 0.6967\n","Epoch 7/50\n","36/36 [==============================] - 1s 19ms/step - loss: 1.5275 - binary_accuracy: 0.8078 - val_loss: 1.5341 - val_binary_accuracy: 0.7633\n","Epoch 8/50\n","36/36 [==============================] - 1s 17ms/step - loss: 1.5068 - binary_accuracy: 0.8333 - val_loss: 1.5160 - val_binary_accuracy: 0.7800\n","Epoch 9/50\n","36/36 [==============================] - 1s 16ms/step - loss: 1.4854 - binary_accuracy: 0.8544 - val_loss: 1.4968 - val_binary_accuracy: 0.8200\n","Epoch 10/50\n","36/36 [==============================] - 1s 15ms/step - loss: 1.4604 - binary_accuracy: 0.8767 - val_loss: 1.4711 - val_binary_accuracy: 0.8067\n","Epoch 11/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4271 - binary_accuracy: 0.8833 - val_loss: 1.4421 - val_binary_accuracy: 0.7867\n","Epoch 12/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3944 - binary_accuracy: 0.8933 - val_loss: 1.4150 - val_binary_accuracy: 0.8167\n","Epoch 13/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3641 - binary_accuracy: 0.8956 - val_loss: 1.3905 - val_binary_accuracy: 0.8433\n","Epoch 14/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3348 - binary_accuracy: 0.9144 - val_loss: 1.3672 - val_binary_accuracy: 0.8433\n","Epoch 15/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3068 - binary_accuracy: 0.9256 - val_loss: 1.3469 - val_binary_accuracy: 0.8300\n","Epoch 16/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2815 - binary_accuracy: 0.9256 - val_loss: 1.3243 - val_binary_accuracy: 0.8400\n","Epoch 17/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2562 - binary_accuracy: 0.9344 - val_loss: 1.3043 - val_binary_accuracy: 0.8533\n","Epoch 18/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2320 - binary_accuracy: 0.9400 - val_loss: 1.2853 - val_binary_accuracy: 0.8567\n","Epoch 19/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2093 - binary_accuracy: 0.9444 - val_loss: 1.2670 - val_binary_accuracy: 0.8600\n","Epoch 20/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1870 - binary_accuracy: 0.9489 - val_loss: 1.2495 - val_binary_accuracy: 0.8667\n","Epoch 21/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1653 - binary_accuracy: 0.9511 - val_loss: 1.2325 - val_binary_accuracy: 0.8700\n","Epoch 22/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1446 - binary_accuracy: 0.9544 - val_loss: 1.2163 - val_binary_accuracy: 0.8700\n","Epoch 23/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1250 - binary_accuracy: 0.9533 - val_loss: 1.2007 - val_binary_accuracy: 0.8700\n","Epoch 24/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1057 - binary_accuracy: 0.9544 - val_loss: 1.1857 - val_binary_accuracy: 0.8667\n","Epoch 25/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0872 - binary_accuracy: 0.9600 - val_loss: 1.1714 - val_binary_accuracy: 0.8700\n","Epoch 26/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0691 - binary_accuracy: 0.9611 - val_loss: 1.1574 - val_binary_accuracy: 0.8733\n","Epoch 27/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0515 - binary_accuracy: 0.9600 - val_loss: 1.1440 - val_binary_accuracy: 0.8700\n","Epoch 28/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0350 - binary_accuracy: 0.9633 - val_loss: 1.1321 - val_binary_accuracy: 0.8667\n","Epoch 29/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0187 - binary_accuracy: 0.9622 - val_loss: 1.1187 - val_binary_accuracy: 0.8767\n","Epoch 30/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0029 - binary_accuracy: 0.9689 - val_loss: 1.1066 - val_binary_accuracy: 0.8733\n","Epoch 31/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9878 - binary_accuracy: 0.9700 - val_loss: 1.0952 - val_binary_accuracy: 0.8733\n","Epoch 32/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9731 - binary_accuracy: 0.9689 - val_loss: 1.0840 - val_binary_accuracy: 0.8767\n","Epoch 33/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9586 - binary_accuracy: 0.9733 - val_loss: 1.0730 - val_binary_accuracy: 0.8767\n","Epoch 34/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9447 - binary_accuracy: 0.9744 - val_loss: 1.0624 - val_binary_accuracy: 0.8733\n","Epoch 35/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9311 - binary_accuracy: 0.9689 - val_loss: 1.0525 - val_binary_accuracy: 0.8767\n","Epoch 36/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9177 - binary_accuracy: 0.9744 - val_loss: 1.0423 - val_binary_accuracy: 0.8733\n","Epoch 37/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9049 - binary_accuracy: 0.9756 - val_loss: 1.0334 - val_binary_accuracy: 0.8667\n","Epoch 38/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8922 - binary_accuracy: 0.9744 - val_loss: 1.0245 - val_binary_accuracy: 0.8667\n","Epoch 39/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8801 - binary_accuracy: 0.9767 - val_loss: 1.0143 - val_binary_accuracy: 0.8633\n","Epoch 40/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8681 - binary_accuracy: 0.9767 - val_loss: 1.0048 - val_binary_accuracy: 0.8733\n","Epoch 41/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8564 - binary_accuracy: 0.9767 - val_loss: 0.9962 - val_binary_accuracy: 0.8667\n","Epoch 42/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8451 - binary_accuracy: 0.9767 - val_loss: 0.9880 - val_binary_accuracy: 0.8633\n","Epoch 43/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8341 - binary_accuracy: 0.9778 - val_loss: 0.9796 - val_binary_accuracy: 0.8667\n","Epoch 44/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8232 - binary_accuracy: 0.9789 - val_loss: 0.9716 - val_binary_accuracy: 0.8667\n","Epoch 45/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8127 - binary_accuracy: 0.9811 - val_loss: 0.9642 - val_binary_accuracy: 0.8633\n","Epoch 46/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8026 - binary_accuracy: 0.9811 - val_loss: 0.9572 - val_binary_accuracy: 0.8633\n","Epoch 47/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.7923 - binary_accuracy: 0.9811 - val_loss: 0.9490 - val_binary_accuracy: 0.8633\n","Epoch 48/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.7825 - binary_accuracy: 0.9833 - val_loss: 0.9426 - val_binary_accuracy: 0.8633\n","Epoch 49/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.7728 - binary_accuracy: 0.9811 - val_loss: 0.9346 - val_binary_accuracy: 0.8633\n","Epoch 50/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.7634 - binary_accuracy: 0.9844 - val_loss: 0.9281 - val_binary_accuracy: 0.8633\n","Epoch 1/50\n","36/36 [==============================] - 1s 16ms/step - loss: 1.6352 - binary_accuracy: 0.5000 - val_loss: 1.6225 - val_binary_accuracy: 0.5667\n","Epoch 2/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.6119 - binary_accuracy: 0.5933 - val_loss: 1.6070 - val_binary_accuracy: 0.6100\n","Epoch 3/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.5889 - binary_accuracy: 0.6589 - val_loss: 1.5867 - val_binary_accuracy: 0.6367\n","Epoch 4/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5633 - binary_accuracy: 0.6733 - val_loss: 1.5668 - val_binary_accuracy: 0.6667\n","Epoch 5/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5343 - binary_accuracy: 0.7178 - val_loss: 1.5470 - val_binary_accuracy: 0.7133\n","Epoch 6/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5049 - binary_accuracy: 0.7633 - val_loss: 1.5252 - val_binary_accuracy: 0.7333\n","Epoch 7/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4754 - binary_accuracy: 0.8067 - val_loss: 1.5038 - val_binary_accuracy: 0.7167\n","Epoch 8/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4478 - binary_accuracy: 0.8311 - val_loss: 1.4842 - val_binary_accuracy: 0.7533\n","Epoch 9/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4206 - binary_accuracy: 0.8544 - val_loss: 1.4651 - val_binary_accuracy: 0.7733\n","Epoch 10/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3949 - binary_accuracy: 0.8644 - val_loss: 1.4468 - val_binary_accuracy: 0.7900\n","Epoch 11/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3704 - binary_accuracy: 0.8811 - val_loss: 1.4284 - val_binary_accuracy: 0.7967\n","Epoch 12/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3465 - binary_accuracy: 0.8967 - val_loss: 1.4110 - val_binary_accuracy: 0.8000\n","Epoch 13/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3236 - binary_accuracy: 0.9122 - val_loss: 1.3941 - val_binary_accuracy: 0.8067\n","Epoch 14/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3007 - binary_accuracy: 0.9244 - val_loss: 1.3782 - val_binary_accuracy: 0.7867\n","Epoch 15/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2792 - binary_accuracy: 0.9244 - val_loss: 1.3618 - val_binary_accuracy: 0.8100\n","Epoch 16/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2575 - binary_accuracy: 0.9289 - val_loss: 1.3457 - val_binary_accuracy: 0.8200\n","Epoch 17/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2367 - binary_accuracy: 0.9389 - val_loss: 1.3303 - val_binary_accuracy: 0.8300\n","Epoch 18/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2164 - binary_accuracy: 0.9389 - val_loss: 1.3152 - val_binary_accuracy: 0.8433\n","Epoch 19/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1963 - binary_accuracy: 0.9489 - val_loss: 1.3020 - val_binary_accuracy: 0.8267\n","Epoch 20/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1780 - binary_accuracy: 0.9500 - val_loss: 1.2868 - val_binary_accuracy: 0.8467\n","Epoch 21/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1591 - binary_accuracy: 0.9489 - val_loss: 1.2728 - val_binary_accuracy: 0.8433\n","Epoch 22/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1408 - binary_accuracy: 0.9533 - val_loss: 1.2595 - val_binary_accuracy: 0.8433\n","Epoch 23/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1228 - binary_accuracy: 0.9578 - val_loss: 1.2462 - val_binary_accuracy: 0.8567\n","Epoch 24/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1057 - binary_accuracy: 0.9600 - val_loss: 1.2338 - val_binary_accuracy: 0.8433\n","Epoch 25/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0892 - binary_accuracy: 0.9622 - val_loss: 1.2216 - val_binary_accuracy: 0.8500\n","Epoch 26/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0727 - binary_accuracy: 0.9644 - val_loss: 1.2090 - val_binary_accuracy: 0.8533\n","Epoch 27/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0570 - binary_accuracy: 0.9678 - val_loss: 1.1973 - val_binary_accuracy: 0.8533\n","Epoch 28/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0416 - binary_accuracy: 0.9700 - val_loss: 1.1856 - val_binary_accuracy: 0.8633\n","Epoch 29/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0265 - binary_accuracy: 0.9756 - val_loss: 1.1743 - val_binary_accuracy: 0.8633\n","Epoch 30/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0122 - binary_accuracy: 0.9744 - val_loss: 1.1637 - val_binary_accuracy: 0.8633\n","Epoch 31/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9980 - binary_accuracy: 0.9767 - val_loss: 1.1535 - val_binary_accuracy: 0.8633\n","Epoch 32/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9841 - binary_accuracy: 0.9778 - val_loss: 1.1428 - val_binary_accuracy: 0.8700\n","Epoch 33/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9707 - binary_accuracy: 0.9800 - val_loss: 1.1335 - val_binary_accuracy: 0.8667\n","Epoch 34/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9576 - binary_accuracy: 0.9778 - val_loss: 1.1231 - val_binary_accuracy: 0.8667\n","Epoch 35/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9449 - binary_accuracy: 0.9778 - val_loss: 1.1139 - val_binary_accuracy: 0.8700\n","Epoch 36/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9326 - binary_accuracy: 0.9811 - val_loss: 1.1049 - val_binary_accuracy: 0.8667\n","Epoch 37/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9204 - binary_accuracy: 0.9833 - val_loss: 1.0962 - val_binary_accuracy: 0.8633\n","Epoch 38/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9087 - binary_accuracy: 0.9822 - val_loss: 1.0878 - val_binary_accuracy: 0.8667\n","Epoch 39/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8971 - binary_accuracy: 0.9833 - val_loss: 1.0785 - val_binary_accuracy: 0.8700\n","Epoch 40/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8858 - binary_accuracy: 0.9844 - val_loss: 1.0714 - val_binary_accuracy: 0.8700\n","Epoch 41/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8748 - binary_accuracy: 0.9833 - val_loss: 1.0621 - val_binary_accuracy: 0.8700\n","Epoch 42/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8640 - binary_accuracy: 0.9867 - val_loss: 1.0543 - val_binary_accuracy: 0.8700\n","Epoch 43/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8536 - binary_accuracy: 0.9867 - val_loss: 1.0469 - val_binary_accuracy: 0.8667\n","Epoch 44/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8432 - binary_accuracy: 0.9867 - val_loss: 1.0396 - val_binary_accuracy: 0.8667\n","Epoch 45/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8332 - binary_accuracy: 0.9867 - val_loss: 1.0326 - val_binary_accuracy: 0.8700\n","Epoch 46/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8232 - binary_accuracy: 0.9867 - val_loss: 1.0245 - val_binary_accuracy: 0.8667\n","Epoch 47/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8137 - binary_accuracy: 0.9867 - val_loss: 1.0187 - val_binary_accuracy: 0.8767\n","Epoch 48/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8041 - binary_accuracy: 0.9878 - val_loss: 1.0110 - val_binary_accuracy: 0.8667\n","Epoch 49/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.7947 - binary_accuracy: 0.9878 - val_loss: 1.0051 - val_binary_accuracy: 0.8767\n","Epoch 50/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.7857 - binary_accuracy: 0.9889 - val_loss: 0.9980 - val_binary_accuracy: 0.8667\n","Epoch 1/50\n","36/36 [==============================] - 1s 16ms/step - loss: 1.6311 - binary_accuracy: 0.5156 - val_loss: 1.6282 - val_binary_accuracy: 0.5133\n","Epoch 2/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.6163 - binary_accuracy: 0.5600 - val_loss: 1.6172 - val_binary_accuracy: 0.5267\n","Epoch 3/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.6004 - binary_accuracy: 0.6089 - val_loss: 1.6055 - val_binary_accuracy: 0.5367\n","Epoch 4/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5821 - binary_accuracy: 0.6622 - val_loss: 1.5930 - val_binary_accuracy: 0.5600\n","Epoch 5/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5618 - binary_accuracy: 0.6944 - val_loss: 1.5789 - val_binary_accuracy: 0.5900\n","Epoch 6/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5401 - binary_accuracy: 0.7344 - val_loss: 1.5637 - val_binary_accuracy: 0.6000\n","Epoch 7/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5172 - binary_accuracy: 0.7533 - val_loss: 1.5477 - val_binary_accuracy: 0.6400\n","Epoch 8/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4934 - binary_accuracy: 0.7933 - val_loss: 1.5319 - val_binary_accuracy: 0.6467\n","Epoch 9/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4690 - binary_accuracy: 0.8244 - val_loss: 1.5155 - val_binary_accuracy: 0.6600\n","Epoch 10/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4447 - binary_accuracy: 0.8389 - val_loss: 1.4980 - val_binary_accuracy: 0.6800\n","Epoch 11/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4202 - binary_accuracy: 0.8478 - val_loss: 1.4794 - val_binary_accuracy: 0.7233\n","Epoch 12/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3964 - binary_accuracy: 0.8822 - val_loss: 1.4627 - val_binary_accuracy: 0.7333\n","Epoch 13/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3725 - binary_accuracy: 0.8967 - val_loss: 1.4456 - val_binary_accuracy: 0.7300\n","Epoch 14/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3490 - binary_accuracy: 0.9111 - val_loss: 1.4306 - val_binary_accuracy: 0.7333\n","Epoch 15/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3260 - binary_accuracy: 0.9111 - val_loss: 1.4136 - val_binary_accuracy: 0.7433\n","Epoch 16/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3035 - binary_accuracy: 0.9167 - val_loss: 1.3977 - val_binary_accuracy: 0.7467\n","Epoch 17/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2812 - binary_accuracy: 0.9244 - val_loss: 1.3835 - val_binary_accuracy: 0.7467\n","Epoch 18/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2597 - binary_accuracy: 0.9256 - val_loss: 1.3652 - val_binary_accuracy: 0.7767\n","Epoch 19/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2385 - binary_accuracy: 0.9289 - val_loss: 1.3512 - val_binary_accuracy: 0.7767\n","Epoch 20/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2181 - binary_accuracy: 0.9311 - val_loss: 1.3359 - val_binary_accuracy: 0.7767\n","Epoch 21/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1977 - binary_accuracy: 0.9389 - val_loss: 1.3205 - val_binary_accuracy: 0.7933\n","Epoch 22/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1780 - binary_accuracy: 0.9422 - val_loss: 1.3064 - val_binary_accuracy: 0.7933\n","Epoch 23/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1589 - binary_accuracy: 0.9500 - val_loss: 1.2935 - val_binary_accuracy: 0.7867\n","Epoch 24/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1401 - binary_accuracy: 0.9522 - val_loss: 1.2796 - val_binary_accuracy: 0.7933\n","Epoch 25/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1219 - binary_accuracy: 0.9556 - val_loss: 1.2664 - val_binary_accuracy: 0.8067\n","Epoch 26/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1038 - binary_accuracy: 0.9533 - val_loss: 1.2529 - val_binary_accuracy: 0.8067\n","Epoch 27/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0866 - binary_accuracy: 0.9556 - val_loss: 1.2413 - val_binary_accuracy: 0.8067\n","Epoch 28/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0697 - binary_accuracy: 0.9556 - val_loss: 1.2284 - val_binary_accuracy: 0.8067\n","Epoch 29/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0530 - binary_accuracy: 0.9611 - val_loss: 1.2177 - val_binary_accuracy: 0.8000\n","Epoch 30/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0370 - binary_accuracy: 0.9611 - val_loss: 1.2054 - val_binary_accuracy: 0.8067\n","Epoch 31/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0214 - binary_accuracy: 0.9611 - val_loss: 1.1947 - val_binary_accuracy: 0.8133\n","Epoch 32/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0062 - binary_accuracy: 0.9622 - val_loss: 1.1828 - val_binary_accuracy: 0.8100\n","Epoch 33/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9913 - binary_accuracy: 0.9633 - val_loss: 1.1729 - val_binary_accuracy: 0.8133\n","Epoch 34/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9769 - binary_accuracy: 0.9633 - val_loss: 1.1615 - val_binary_accuracy: 0.8167\n","Epoch 35/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9630 - binary_accuracy: 0.9633 - val_loss: 1.1511 - val_binary_accuracy: 0.8167\n","Epoch 36/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9492 - binary_accuracy: 0.9644 - val_loss: 1.1423 - val_binary_accuracy: 0.8167\n","Epoch 37/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9358 - binary_accuracy: 0.9656 - val_loss: 1.1318 - val_binary_accuracy: 0.8200\n","Epoch 38/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9225 - binary_accuracy: 0.9711 - val_loss: 1.1204 - val_binary_accuracy: 0.8267\n","Epoch 39/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9099 - binary_accuracy: 0.9722 - val_loss: 1.1126 - val_binary_accuracy: 0.8200\n","Epoch 40/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8974 - binary_accuracy: 0.9711 - val_loss: 1.1020 - val_binary_accuracy: 0.8267\n","Epoch 41/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8857 - binary_accuracy: 0.9756 - val_loss: 1.0943 - val_binary_accuracy: 0.8300\n","Epoch 42/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8737 - binary_accuracy: 0.9767 - val_loss: 1.0873 - val_binary_accuracy: 0.8167\n","Epoch 43/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8623 - binary_accuracy: 0.9756 - val_loss: 1.0772 - val_binary_accuracy: 0.8333\n","Epoch 44/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8510 - binary_accuracy: 0.9767 - val_loss: 1.0695 - val_binary_accuracy: 0.8333\n","Epoch 45/50\n","36/36 [==============================] - 1s 24ms/step - loss: 0.8397 - binary_accuracy: 0.9756 - val_loss: 1.0599 - val_binary_accuracy: 0.8367\n","Epoch 46/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8295 - binary_accuracy: 0.9789 - val_loss: 1.0527 - val_binary_accuracy: 0.8300\n","Epoch 47/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8190 - binary_accuracy: 0.9800 - val_loss: 1.0459 - val_binary_accuracy: 0.8333\n","Epoch 48/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8087 - binary_accuracy: 0.9800 - val_loss: 1.0381 - val_binary_accuracy: 0.8333\n","Epoch 49/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.7986 - binary_accuracy: 0.9833 - val_loss: 1.0307 - val_binary_accuracy: 0.8367\n","Epoch 50/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.7887 - binary_accuracy: 0.9833 - val_loss: 1.0228 - val_binary_accuracy: 0.8367\n","Epoch 1/50\n","36/36 [==============================] - 1s 18ms/step - loss: 1.6298 - binary_accuracy: 0.5022 - val_loss: 1.6175 - val_binary_accuracy: 0.5300\n","Epoch 2/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.6109 - binary_accuracy: 0.5644 - val_loss: 1.6063 - val_binary_accuracy: 0.5467\n","Epoch 3/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5921 - binary_accuracy: 0.6111 - val_loss: 1.5944 - val_binary_accuracy: 0.5533\n","Epoch 4/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5726 - binary_accuracy: 0.6500 - val_loss: 1.5807 - val_binary_accuracy: 0.5600\n","Epoch 5/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5512 - binary_accuracy: 0.6811 - val_loss: 1.5660 - val_binary_accuracy: 0.6033\n","Epoch 6/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5282 - binary_accuracy: 0.7456 - val_loss: 1.5506 - val_binary_accuracy: 0.6267\n","Epoch 7/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.5045 - binary_accuracy: 0.7400 - val_loss: 1.5337 - val_binary_accuracy: 0.6833\n","Epoch 8/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4803 - binary_accuracy: 0.7911 - val_loss: 1.5174 - val_binary_accuracy: 0.6900\n","Epoch 9/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4559 - binary_accuracy: 0.8178 - val_loss: 1.5010 - val_binary_accuracy: 0.6900\n","Epoch 10/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.4319 - binary_accuracy: 0.8378 - val_loss: 1.4837 - val_binary_accuracy: 0.7067\n","Epoch 11/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.4080 - binary_accuracy: 0.8633 - val_loss: 1.4668 - val_binary_accuracy: 0.7267\n","Epoch 12/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3843 - binary_accuracy: 0.8811 - val_loss: 1.4495 - val_binary_accuracy: 0.7500\n","Epoch 13/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3614 - binary_accuracy: 0.8933 - val_loss: 1.4319 - val_binary_accuracy: 0.7867\n","Epoch 14/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.3386 - binary_accuracy: 0.9067 - val_loss: 1.4152 - val_binary_accuracy: 0.7933\n","Epoch 15/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.3168 - binary_accuracy: 0.9200 - val_loss: 1.3989 - val_binary_accuracy: 0.8067\n","Epoch 16/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.2949 - binary_accuracy: 0.9300 - val_loss: 1.3824 - val_binary_accuracy: 0.8100\n","Epoch 17/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2741 - binary_accuracy: 0.9378 - val_loss: 1.3674 - val_binary_accuracy: 0.8067\n","Epoch 18/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2532 - binary_accuracy: 0.9389 - val_loss: 1.3496 - val_binary_accuracy: 0.8433\n","Epoch 19/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2330 - binary_accuracy: 0.9467 - val_loss: 1.3359 - val_binary_accuracy: 0.8167\n","Epoch 20/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.2133 - binary_accuracy: 0.9511 - val_loss: 1.3191 - val_binary_accuracy: 0.8433\n","Epoch 21/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1940 - binary_accuracy: 0.9533 - val_loss: 1.3045 - val_binary_accuracy: 0.8367\n","Epoch 22/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1751 - binary_accuracy: 0.9578 - val_loss: 1.2906 - val_binary_accuracy: 0.8233\n","Epoch 23/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1568 - binary_accuracy: 0.9589 - val_loss: 1.2752 - val_binary_accuracy: 0.8400\n","Epoch 24/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.1389 - binary_accuracy: 0.9611 - val_loss: 1.2618 - val_binary_accuracy: 0.8367\n","Epoch 25/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1215 - binary_accuracy: 0.9600 - val_loss: 1.2488 - val_binary_accuracy: 0.8367\n","Epoch 26/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.1047 - binary_accuracy: 0.9611 - val_loss: 1.2339 - val_binary_accuracy: 0.8567\n","Epoch 27/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0879 - binary_accuracy: 0.9622 - val_loss: 1.2201 - val_binary_accuracy: 0.8667\n","Epoch 28/50\n","36/36 [==============================] - 1s 20ms/step - loss: 1.0723 - binary_accuracy: 0.9622 - val_loss: 1.2096 - val_binary_accuracy: 0.8467\n","Epoch 29/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0567 - binary_accuracy: 0.9611 - val_loss: 1.1971 - val_binary_accuracy: 0.8567\n","Epoch 30/50\n","36/36 [==============================] - 0s 12ms/step - loss: 1.0414 - binary_accuracy: 0.9633 - val_loss: 1.1877 - val_binary_accuracy: 0.8433\n","Epoch 31/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0265 - binary_accuracy: 0.9644 - val_loss: 1.1729 - val_binary_accuracy: 0.8733\n","Epoch 32/50\n","36/36 [==============================] - 0s 11ms/step - loss: 1.0124 - binary_accuracy: 0.9656 - val_loss: 1.1618 - val_binary_accuracy: 0.8667\n","Epoch 33/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9984 - binary_accuracy: 0.9656 - val_loss: 1.1513 - val_binary_accuracy: 0.8633\n","Epoch 34/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9849 - binary_accuracy: 0.9667 - val_loss: 1.1408 - val_binary_accuracy: 0.8600\n","Epoch 35/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9715 - binary_accuracy: 0.9689 - val_loss: 1.1316 - val_binary_accuracy: 0.8567\n","Epoch 36/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9587 - binary_accuracy: 0.9711 - val_loss: 1.1226 - val_binary_accuracy: 0.8567\n","Epoch 37/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.9461 - binary_accuracy: 0.9733 - val_loss: 1.1120 - val_binary_accuracy: 0.8633\n","Epoch 38/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9340 - binary_accuracy: 0.9744 - val_loss: 1.1024 - val_binary_accuracy: 0.8600\n","Epoch 39/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9220 - binary_accuracy: 0.9767 - val_loss: 1.0934 - val_binary_accuracy: 0.8600\n","Epoch 40/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.9101 - binary_accuracy: 0.9789 - val_loss: 1.0838 - val_binary_accuracy: 0.8600\n","Epoch 41/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8991 - binary_accuracy: 0.9778 - val_loss: 1.0744 - val_binary_accuracy: 0.8633\n","Epoch 42/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8880 - binary_accuracy: 0.9800 - val_loss: 1.0651 - val_binary_accuracy: 0.8667\n","Epoch 43/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8770 - binary_accuracy: 0.9800 - val_loss: 1.0560 - val_binary_accuracy: 0.8700\n","Epoch 44/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8665 - binary_accuracy: 0.9833 - val_loss: 1.0476 - val_binary_accuracy: 0.8733\n","Epoch 45/50\n","36/36 [==============================] - 0s 13ms/step - loss: 0.8562 - binary_accuracy: 0.9822 - val_loss: 1.0404 - val_binary_accuracy: 0.8600\n","Epoch 46/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8461 - binary_accuracy: 0.9844 - val_loss: 1.0339 - val_binary_accuracy: 0.8633\n","Epoch 47/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8360 - binary_accuracy: 0.9844 - val_loss: 1.0260 - val_binary_accuracy: 0.8667\n","Epoch 48/50\n","36/36 [==============================] - 0s 13ms/step - loss: 0.8261 - binary_accuracy: 0.9856 - val_loss: 1.0218 - val_binary_accuracy: 0.8567\n","Epoch 49/50\n","36/36 [==============================] - 0s 11ms/step - loss: 0.8167 - binary_accuracy: 0.9856 - val_loss: 1.0120 - val_binary_accuracy: 0.8667\n","Epoch 50/50\n","36/36 [==============================] - 0s 12ms/step - loss: 0.8071 - binary_accuracy: 0.9867 - val_loss: 1.0018 - val_binary_accuracy: 0.8667\n"]}]},{"cell_type":"code","source":["# Plot validation performance. \n","plt.plot(average_loss_history,c='r')\n","plt.plot(average_acc_history,c=\"r\",linestyle=\"dashed\")\n","plt.plot(average_val_loss_history,c='b')\n","plt.plot(average_val_acc_history,c='b',linestyle=\"dashed\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend(['Training Loss','Training Accuracy','Validation Loss','Validation Accuracy'])\n","plt.show()"],"metadata":{"id":"rRmEzDzHVeh9"},"execution_count":null,"outputs":[]}]}